---
title: "2. Building eval datasets"
description: Curate queries and ground truth that represent real usage without leaking or biasing results.

---

<Callout type="warn" title="Status: Stub">
This chapter is a stub.
</Callout>

## Planned topics

- Where to get queries (logs, seeded scenarios, synthetic with review)
- Ground truth strategies: doc-level vs passage-level labels
- Dataset maintenance as content evolves

## Optional: how this maps to Unrag

Unrag includes an eval harness for deterministic retrieval evaluation. See `/docs/eval`.

