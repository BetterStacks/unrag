---
title: API
description: Method reference for the vendored Google Drive connector module.
---

The connector ships as vendored code inside your Unrag install directory at `<installDir>/connectors/google-drive/**`. In application code you typically import from your alias base:

```ts
import { googleDriveConnector } from "@unrag/connectors/google-drive";
```

## Primary API

### `googleDriveConnector.streamFiles(input)`

This is the main entry point for syncing Google Drive files. It returns an async iterable that yields connector events—upserts, warnings, progress updates, and checkpoints. You consume this stream via `engine.runConnectorStream(...)`.

```ts
const stream = googleDriveConnector.streamFiles({
  auth: {
    kind: "service_account",
    credentialsJson: process.env.GOOGLE_SERVICE_ACCOUNT_JSON!,
  },
  fileIds: ["1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs"],
});

const result = await engine.runConnectorStream({ stream });
```

The runner applies each event to your engine and returns a summary:

<TypeTable
  type={{
    upserts: {
      description: 'Number of files successfully ingested.',
      type: 'number',
    },
    deletes: {
      description: 'Number of documents deleted (when deleteOnNotFound is enabled).',
      type: 'number',
    },
    warnings: {
      description: 'Number of warning events (failed files, not-found files, skipped files, etc.).',
      type: 'number',
    },
    lastCheckpoint: {
      description: 'The final checkpoint emitted by the stream, if any.',
      type: 'GoogleDriveCheckpoint | undefined',
    },
  }}
/>

### streamFiles input

<TypeTable
  type={{
    auth: {
      description: 'A GoogleDriveAuth object describing how to authenticate. See Auth patterns below.',
      type: 'GoogleDriveAuth',
    },
    fileIds: {
      description: 'Array of Google Drive file IDs. The connector fetches metadata and content for each file.',
      type: 'string[]',
    },
    sourceIdPrefix: {
      description: 'Prepends a namespace to every sourceId. Useful for multi-tenant apps to partition content by tenant.',
      type: 'string',
      default: 'undefined',
    },
    deleteOnNotFound: {
      description: 'Delete the previously ingested document if a file is not found or inaccessible.',
      type: 'boolean',
      default: 'false',
    },
    checkpoint: {
      description: 'Optional checkpoint to resume from. Pass the last persisted checkpoint to continue an interrupted sync.',
      type: 'GoogleDriveCheckpoint',
      default: 'undefined',
    },
    options: {
      description: 'Additional configuration for connector behavior (maxBytesPerFile, treatForbiddenAsNotFound, strictNativeExport).',
      type: 'StreamGoogleDriveFilesOptions',
      default: 'undefined',
    },
  }}
/>

`sourceIdPrefix` prepends a namespace to every `sourceId`. This is useful for multi-tenant apps where you want to partition content by tenant:

```ts
const stream = googleDriveConnector.streamFiles({
  auth,
  fileIds: ["1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs"],
  sourceIdPrefix: `tenant:${tenantId}:`,
});

await engine.runConnectorStream({ stream });
```

With a prefix, the resulting source IDs look like `tenant:acme:gdrive:file:<fileId>`. You can then retrieve with `scope: { sourceId: "tenant:acme:" }` to search only that tenant's content.

`deleteOnNotFound` tells the connector to emit a delete event if a file is not found or inaccessible. This is useful when you keep a static list of file IDs and want your index to reflect reality after permissions change or a file is deleted:

```ts
const stream = googleDriveConnector.streamFiles({
  auth,
  fileIds: ["1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs"],
  deleteOnNotFound: true,
});

await engine.runConnectorStream({ stream });
```

`options` provides additional knobs for controlling connector behavior:

```ts
const stream = googleDriveConnector.streamFiles({
  auth,
  fileIds,
  options: {
    maxBytesPerFile: 20 * 1024 * 1024, // Skip files larger than 20MB
    treatForbiddenAsNotFound: true,    // Default: treat 403 as not-found for cleanup
    strictNativeExport: false,         // Default: fall back to binary export if text export fails
  },
});

await engine.runConnectorStream({ stream });
```

<TypeTable
  type={{
    maxBytesPerFile: {
      description: 'Skip files larger than this size in bytes.',
      type: 'number',
      default: '15 * 1024 * 1024 (15 MB)',
    },
    treatForbiddenAsNotFound: {
      description: 'Treat HTTP 403 (forbidden) responses as not-found for cleanup purposes.',
      type: 'boolean',
      default: 'true',
    },
    strictNativeExport: {
      description: 'If true, fail when Google-native files cannot be exported to text. If false, fall back to binary export.',
      type: 'boolean',
      default: 'false',
    },
  }}
/>

## Consuming the stream

The recommended way to consume a connector stream is via `engine.runConnectorStream(...)`, which handles all event types automatically:

```ts
const result = await engine.runConnectorStream({
  stream,
  onEvent: (event) => {
    // Called for every event (progress, warning, upsert, delete, checkpoint)
    console.log(event.type, event);
  },
  onCheckpoint: async (checkpoint) => {
    // Called specifically for checkpoint events
    await persistCheckpoint(checkpoint);
  },
  signal: abortController.signal, // Optional: abort early
});
```

### `loadGoogleDriveFileDocument(args)`

This lower-level helper loads a single file and returns a normalized document shape with `sourceId`, `content`, `metadata`, and `assets`. Use it when you want to add custom metadata, control chunking, or decide exactly how ingestion happens.

```ts
import { createUnragEngine } from "@unrag/config";
import { createGoogleDriveClient, loadGoogleDriveFileDocument } from "@unrag/connectors/google-drive";

export async function ingestWithCustomMetadata() {
  const engine = createUnragEngine();
  
  const { drive } = await createGoogleDriveClient({
    auth: {
      kind: "service_account",
      credentialsJson: process.env.GOOGLE_SERVICE_ACCOUNT_JSON!,
    },
  });

  const doc = await loadGoogleDriveFileDocument({
    drive,
    fileId: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs",
    sourceIdPrefix: "docs:",
  });

  const result = await engine.ingest({
    sourceId: doc.sourceId,
    content: doc.content,
    assets: doc.assets,
    metadata: {
      ...doc.metadata,
      importedBy: "drive-sync",
      visibility: "internal",
    },
    chunking: { chunkSize: 300, chunkOverlap: 50 },
  });

  if (result.warnings.length > 0) {
    console.warn("unrag ingest warnings", result.warnings);
  }
}
```

The `options` parameter accepts `maxBytesPerFile` and `strictNativeExport` to control file size limits and export behavior.

### `buildGoogleDriveFileIngestInput(args)`

A pure helper function that constructs the `IngestInput` shape for a Drive file. This is what the connector uses internally, exposed for advanced customization:

```ts
import { buildGoogleDriveFileIngestInput } from "@unrag/connectors/google-drive";

const input = buildGoogleDriveFileIngestInput({
  fileId: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs",
  content: "Extracted document text...",
  assets: [],
  metadata: { customField: "value" },
  sourceIdPrefix: "tenant:acme:",
});

// input.sourceId === "tenant:acme:gdrive:file:1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs"
```

## Auth patterns

The `GoogleDriveAuth` type is a union that supports multiple authentication approaches. You pass the variant that matches your setup.

| Auth Kind | Use Case |
|-----------|----------|
| `oauth` with client | When your app already has an OAuth2 client from Google's auth library |
| `oauth` from credentials | When you have OAuth credentials and a refresh token but no client instance |
| `service_account` | For files explicitly shared with a service account |
| `service_account` with subject | For Workspace organizations with domain-wide delegation |
| `google_auth` | Escape hatch for custom auth setups |

### OAuth2 with existing client

If your application already has an OAuth2 client from Google's auth library (perhaps from your login flow), pass it directly:

```ts
import { OAuth2Client } from "google-auth-library";

const oauthClient = new OAuth2Client(clientId, clientSecret, redirectUri);
oauthClient.setCredentials({ refresh_token: userRefreshToken });

const stream = googleDriveConnector.streamFiles({
  auth: { kind: "oauth", oauthClient },
  fileIds,
});

await engine.runConnectorStream({ stream });
```

### OAuth2 from credentials

If you have the OAuth credentials and a refresh token but no client instance, the connector will construct one:

```ts
const stream = googleDriveConnector.streamFiles({
  auth: {
    kind: "oauth",
    clientId: process.env.GOOGLE_CLIENT_ID!,
    clientSecret: process.env.GOOGLE_CLIENT_SECRET!,
    redirectUri: process.env.GOOGLE_REDIRECT_URI!,
    refreshToken: userRefreshToken,
    accessToken: optionalAccessToken, // Optional, will be refreshed if missing
  },
  fileIds,
});

await engine.runConnectorStream({ stream });
```

### Service account (direct access)

For files explicitly shared with the service account:

```ts
const stream = googleDriveConnector.streamFiles({
  auth: {
    kind: "service_account",
    credentialsJson: process.env.GOOGLE_SERVICE_ACCOUNT_JSON!,
    // credentialsJson can be a string (the JSON file contents) or a parsed object
  },
  fileIds,
});

await engine.runConnectorStream({ stream });
```

### Service account with domain-wide delegation

For Workspace organizations with DWD configured, add `subject` to impersonate a user:

```ts
const stream = googleDriveConnector.streamFiles({
  auth: {
    kind: "service_account",
    credentialsJson: process.env.GOOGLE_SERVICE_ACCOUNT_JSON!,
    subject: "user@yourcompany.com",
  },
  fileIds,
});

await engine.runConnectorStream({ stream });
```

The service account will access Drive as if it were that user, seeing all files the user can access.

### Escape hatch: pre-built GoogleAuth

If you have a custom auth setup that doesn't fit the above patterns, pass a pre-configured `GoogleAuth` instance:

```ts
import { GoogleAuth } from "google-auth-library";

const customAuth = new GoogleAuth({
  // Your custom configuration
});

const stream = googleDriveConnector.streamFiles({
  auth: { kind: "google_auth", auth: customAuth },
  fileIds,
});

await engine.runConnectorStream({ stream });
```

## Utilities

### `createGoogleDriveClient({ auth, scopes? })`

Creates a Google Drive API client from auth credentials. Returns `{ drive, authClient }` where `drive` is the Drive API v3 client and `authClient` is the underlying auth object.

Most users don't need this unless they want to make custom Drive API calls or build their own sync logic:

```ts
import { createGoogleDriveClient } from "@unrag/connectors/google-drive";

const { drive } = await createGoogleDriveClient({
  auth: {
    kind: "service_account",
    credentialsJson: process.env.GOOGLE_SERVICE_ACCOUNT_JSON!,
  },
  scopes: ["https://www.googleapis.com/auth/drive.readonly"], // Optional override
});

// Now you can make direct Drive API calls
const res = await drive.files.list({ pageSize: 10 });
```

## Listing accessible files

The connector doesn't include a built-in "list everything" helper because Google Drive accounts can contain a lot of content, and listing strategies tend to be application-specific. Instead, the connector exposes `createGoogleDriveClient()`, which gives you the full Drive API client so you can list files in the way that matches your product.

When you're using a service account without domain-wide delegation, the list results are effectively "what has been shared with this service account" (plus anything it owns). With OAuth, the results are what the authenticated user can access.

### Listing all visible files

Here's a simple pagination loop that lists file IDs and basic metadata:

```ts
import { createGoogleDriveClient } from "@unrag/connectors/google-drive";

export async function listAccessibleFiles(auth: any) {
  const { drive } = await createGoogleDriveClient({ auth });

  const files: Array<{ id: string; name?: string; mimeType?: string }> = [];
  let pageToken: string | undefined;

  while (true) {
    const res = await drive.files.list({
      pageSize: 100,
      pageToken,
      supportsAllDrives: true,
      includeItemsFromAllDrives: true,
      fields: "nextPageToken, files(id,name,mimeType)",
    });

    files.push(...(res.data.files ?? []));
    pageToken = res.data.nextPageToken ?? undefined;
    if (!pageToken) break;
  }

  return files;
}
```

Once you have a list of IDs, you can pass them straight into `googleDriveConnector.streamFiles({ fileIds })`.

### Listing files from a folder

If you want folder-based syncing, list the folder contents first and then sync those IDs:

```ts
import { createGoogleDriveClient, googleDriveConnector } from "@unrag/connectors/google-drive";

export async function syncDriveFolder(args: {
  engine: any;
  auth: any;
  folderId: string;
}) {
  const { drive } = await createGoogleDriveClient({ auth: args.auth });

  const fileIds: string[] = [];
  let pageToken: string | undefined;

  while (true) {
    const res = await drive.files.list({
      q: `'${args.folderId}' in parents and trashed = false`,
      pageSize: 100,
      pageToken,
      supportsAllDrives: true,
      includeItemsFromAllDrives: true,
      fields: "nextPageToken, files(id)",
    });

    fileIds.push(...(res.data.files?.map((f: any) => f.id).filter(Boolean) ?? []));
    pageToken = res.data.nextPageToken ?? undefined;
    if (!pageToken) break;
  }

  const stream = googleDriveConnector.streamFiles({
    auth: args.auth,
    fileIds,
  });

  return await args.engine.runConnectorStream({ stream });
}
```

This is a good fit when your users connect a single "knowledge base folder" and you want sync to pick up newly added files automatically.

### Listing files shared with the authenticated user

For OAuth-based apps, you may want to start with files that have been shared with the user. Drive's search syntax supports this with `sharedWithMe = true` (see [Search for files and folders](https://developers.google.com/drive/api/guides/search-files)):

```ts
import { createGoogleDriveClient } from "@unrag/connectors/google-drive";

export async function listSharedWithMe(auth: any) {
  const { drive } = await createGoogleDriveClient({ auth });

  const files: Array<{ id: string; name?: string; mimeType?: string }> = [];
  let pageToken: string | undefined;

  while (true) {
    const res = await drive.files.list({
      q: "sharedWithMe = true and trashed = false",
      pageSize: 100,
      pageToken,
      supportsAllDrives: true,
      includeItemsFromAllDrives: true,
      fields: "nextPageToken, files(id,name,mimeType)",
    });

    files.push(...(res.data.files ?? []));
    pageToken = res.data.nextPageToken ?? undefined;
    if (!pageToken) break;
  }

  return files;
}
```

### MIME type helpers

The connector exports helpers for working with Drive MIME types:

`classifyDriveMimeType(mimeType)` returns a classification: `"folder"`, `"shortcut"`, `"google_native"` (with a `nativeKind`), or `"binary"`.

`getNativeExportPlan(nativeKind)` returns the export strategy for Google-native files: `"content"` (export to text), `"asset"` (export to binary like PNG), or `"unsupported"`.

`assetKindFromMediaType(mediaType)` maps a MIME type to an Unrag asset kind: `"pdf"`, `"image"`, `"audio"`, `"video"`, or `"file"`.

## Stable source IDs

The connector uses a stable scheme for `sourceId` values:

- Without a prefix: `gdrive:file:<fileId>`
- With `sourceIdPrefix`: `<prefix>gdrive:file:<fileId>` (prefix is normalized to include a trailing `:`)

This enables safe re-runs (idempotent ingest), scoped retrieval via `scope.sourceId` prefixes, and deletion per file or per tenant namespace.

## Event types

The stream yields various event types that you can observe via `onEvent`:

| Event Type | Description |
|------------|-------------|
| `progress` (file:start) | Processing begins for a file |
| `progress` (file:success) | File successfully ingested |
| `warning` (file_not_found) | File not found or inaccessible |
| `warning` (file_skipped) | File skipped due to folder, size, or unsupported type |
| `warning` (file_error) | File processing failed with an error |
| `upsert` | Document ready for ingestion |
| `delete` | Document should be deleted (when deleteOnNotFound is true) |
| `checkpoint` | Resumable position marker |

The `file_skipped` warning includes a `reason` field:

| Reason | Description |
|--------|-------------|
| `is_folder` | The file ID points to a folder, not a file |
| `unsupported_google_mime` | Google-native file type that cannot be exported (e.g., Forms, Sites) |
| `too_large` | File exceeds `maxBytesPerFile` limit |
| `shortcut_unresolved` | Shortcut file where the target couldn't be resolved |

---

## Examples

The examples below cover common integration patterns. They assume you've already set up Google Cloud credentials and have the appropriate environment variables available.

### Logging progress with onEvent

The `onEvent` callback fires for each event as the stream progresses. This is useful for logging, progress indicators, or instrumenting failures:

```ts
import { createUnragEngine } from "@unrag/config";
import { googleDriveConnector } from "@unrag/connectors/google-drive";

const engine = createUnragEngine();

const stream = googleDriveConnector.streamFiles({
  auth: {
    kind: "service_account",
    credentialsJson: process.env.GOOGLE_SERVICE_ACCOUNT_JSON!,
  },
  fileIds: [
    "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs",
    "1CyiMVs0XRA5nFMdKvBdBZjgmUUqptlbs",
    "1DziMVs0XRA5nFMdKvBdBZjgmUUqptlbs",
  ],
});

const result = await engine.runConnectorStream({
  stream,
  onEvent: (event) => {
    if (event.type === "progress" && event.message === "file:success") {
      console.log(`✓ Synced ${event.entityId}`);
    } else if (event.type === "warning" && event.code === "file_not_found") {
      console.warn(`⊘ File not found: ${event.data?.fileId}`);
    } else if (event.type === "warning" && event.code === "file_skipped") {
      console.log(`⊘ Skipped: ${event.message}`);
    } else if (event.type === "warning") {
      console.error(`✗ Failed: ${event.message}`);
    }
  },
});

console.log(`Done: ${result.upserts} synced, ${result.warnings} warnings`);
```

### End-to-end: sync, retrieve, and use in a prompt

Here's a complete flow that syncs Drive content, then uses it to answer a question:

```ts
import { createUnragEngine } from "@unrag/config";
import { googleDriveConnector } from "@unrag/connectors/google-drive";
import { generateText } from "ai";
import { openai } from "@ai-sdk/openai";

const engine = createUnragEngine();

// 1. Sync your knowledge base files
const stream = googleDriveConnector.streamFiles({
  auth: {
    kind: "service_account",
    credentialsJson: process.env.GOOGLE_SERVICE_ACCOUNT_JSON!,
  },
  fileIds: [
    "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs", // Product FAQ doc
    "1CyiMVs0XRA5nFMdKvBdBZjgmUUqptlbs", // Pricing sheet
  ],
});

await engine.runConnectorStream({ stream });

// 2. Retrieve relevant chunks for a user question
const question = "What's the pricing for the Pro plan?";

const { chunks } = await engine.retrieve({
  query: question,
  topK: 5,
});

// 3. Build context and generate an answer
const context = chunks.map((c) => c.content).join("\n\n---\n\n");

const { text } = await generateText({
  model: openai("gpt-4o"),
  system: `Answer questions using only the provided context. If the answer isn't in the context, say so.`,
  prompt: `Context:\n${context}\n\nQuestion: ${question}`,
});

console.log(text);
```

### Multi-tenant sync with namespace prefixes

For SaaS apps where each tenant has their own Drive files:

```ts
import { createUnragEngine } from "@unrag/config";
import { googleDriveConnector } from "@unrag/connectors/google-drive";

export async function syncTenantDriveFiles(
  tenantId: string,
  refreshToken: string,
  fileIds: string[]
) {
  const engine = createUnragEngine();

  const stream = googleDriveConnector.streamFiles({
    auth: {
      kind: "oauth",
      clientId: process.env.GOOGLE_CLIENT_ID!,
      clientSecret: process.env.GOOGLE_CLIENT_SECRET!,
      redirectUri: process.env.GOOGLE_REDIRECT_URI!,
      refreshToken,
    },
    fileIds,
    sourceIdPrefix: `tenant:${tenantId}:`,
  });

  return await engine.runConnectorStream({ stream });
}

// Later, retrieve only that tenant's content:
const { chunks } = await engine.retrieve({
  query: "What are our Q3 goals?",
  topK: 5,
  scope: { sourceId: `tenant:${tenantId}:` },
});
```

### Scheduled sync with a cron job

For content that changes over time, run sync on a schedule:

```ts
// scripts/sync-drive-cron.ts
import { createUnragEngine } from "../lib/unrag/config";
import { googleDriveConnector } from "../lib/unrag/connectors/google-drive";

async function main() {
  console.log(`[${new Date().toISOString()}] Starting Drive sync...`);

  const engine = createUnragEngine();
  const fileIds = await fetchFileIdsFromConfig();

  const stream = googleDriveConnector.streamFiles({
    auth: {
      kind: "service_account",
      credentialsJson: process.env.GOOGLE_SERVICE_ACCOUNT_JSON!,
    },
    fileIds,
    deleteOnNotFound: true,
  });

  const result = await engine.runConnectorStream({ stream });

  console.log(`Completed: ${result.upserts} synced, ${result.deletes} deleted, ${result.warnings} warnings`);

  if (result.warnings > 0) {
    process.exitCode = 1;
  }
}

main().catch((err) => {
  console.error("Sync failed:", err);
  process.exitCode = 1;
});
```
